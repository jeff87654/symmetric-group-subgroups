#!/usr/bin/env python3
"""
Enumerate all subgroups of symmetric groups Sn up to isomorphism.

Uses GAP for group computations with fingerprint-based deduplication
to avoid expensive isomorphism tests where possible.

Usage:
    python enumerate_subgroups.py                    # Run S2 through S8
    python enumerate_subgroups.py --max-n 6          # Run S2 through S6
    python enumerate_subgroups.py --start-n 9 --max-n 10  # Continue from S9 to S10
"""

import argparse
import subprocess
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path


def generate_gap_script(start_n: int, max_n: int, db_file: str,
                        log_file: str, groups_file: str, cache_dir: str) -> str:
    """Generate the GAP script for subgroup enumeration."""

    return f'''
# Enumerate subgroups of Sn up to isomorphism
# Generated by enumerate_subgroups.py

startN := {start_n};
maxN := {max_n};
dbFile := "{db_file}";
logFile := "{log_file}";
groupsFile := "{groups_file}";
conjugacyCacheDir := "{cache_dir}";

# ============================================================================
# GroupFingerprint function - computes invariants for a group
# Enhanced with IdSmallGroup for fast identification of small groups
# ============================================================================
GroupFingerprint := function(G)
    local fp, ord, smallId, derivedLen;
    ord := Size(G);
    fp := rec(
        size := ord,
        centerSize := Size(Center(G)),
        derivedSize := Size(DerivedSubgroup(G)),
        frattiniSize := Size(FrattiniSubgroup(G)),
        abelianInvariants := AbelianInvariants(G),
        isAbelian := IsAbelian(G),
        isSolvable := IsSolvable(G),
        isNilpotent := IsNilpotent(G),
        exponent := Exponent(G),
        nrConjugacyClasses := NrConjugacyClasses(G),
        smallGroupId := fail,  # Will be set if available
        derivedLength := fail  # For solvable groups
    );

    # Try to get SmallGroup ID (works for some orders <= 2000)
    # Note: Some orders don't have SmallGroups ID data installed by default
    # These are powers of 2 >= 512, and multiples like 768, 1536
    if ord <= 2000 and ord > 1 and not ord in [512, 768, 1024, 1536] then
        smallId := IdSmallGroup(G);
        if smallId <> fail then
            fp.smallGroupId := smallId;
        fi;
    fi;

    # Derived length for solvable groups (cheap additional invariant)
    if fp.isSolvable then
        fp.derivedLength := DerivedLength(G);
    fi;

    return fp;
end;

# Convert fingerprint to string for hashing
GroupFingerprintKey := function(fp)
    local key, derivedLen;
    # Handle missing derivedLength field from older database entries
    if IsBound(fp.derivedLength) then
        derivedLen := fp.derivedLength;
    else
        derivedLen := fail;
    fi;
    key := Concatenation(
        String(fp.size), "_",
        String(fp.centerSize), "_",
        String(fp.derivedSize), "_",
        String(fp.frattiniSize), "_",
        String(fp.abelianInvariants), "_",
        String(fp.isAbelian), "_",
        String(fp.isSolvable), "_",
        String(fp.isNilpotent), "_",
        String(fp.exponent), "_",
        String(fp.nrConjugacyClasses), "_",
        String(derivedLen)
    );
    # If we have SmallGroupId, append it (makes each bucket size 1!)
    if IsBound(fp.smallGroupId) and fp.smallGroupId <> fail then
        key := Concatenation(key, "_SG", String(fp.smallGroupId));
    fi;
    return key;
end;

# ============================================================================
# Database structure
# ============================================================================
db := rec(
    groups := [],      # List of records
    index := rec()     # fingerprint_key -> [indices]
);

# Statistics
stats := rec(
    totalSubgroups := 0,
    isomorphismTests := 0,
    fingerprintHits := 0
);

# ============================================================================
# Load existing database if it exists
# ============================================================================
LoadDatabase := function(filename)
    local data, entry, G, key, fp, needsRecompute;
    if IsExistingFile(filename) then
        AppendTo(logFile, "Loading existing database from ", filename, "\\n");
        data := ReadAsFunction(filename)();
        for entry in data.groups do
            if Length(entry.generators) = 0 then
                G := Group(());
            else
                G := Group(List(entry.generators, PermList));
            fi;
            # Check if fingerprint needs to be recomputed (missing new fields)
            needsRecompute := not IsBound(entry.fingerprint.derivedLength) or
                              not IsBound(entry.fingerprint.smallGroupId);
            if needsRecompute then
                fp := GroupFingerprint(G);
            else
                fp := entry.fingerprint;
            fi;
            key := GroupFingerprintKey(fp);
            Add(db.groups, rec(
                fingerprint := fp,
                generators := entry.generators,
                structure := entry.structure,
                firstFoundIn := entry.firstFoundIn,
                degree := entry.degree
            ));
            if not IsBound(db.index.(key)) then
                db.index.(key) := [];
            fi;
            Add(db.index.(key), Length(db.groups));
        od;
        AppendTo(logFile, "Loaded ", Length(db.groups), " groups from database\\n");
    else
        AppendTo(logFile, "No existing database found, starting fresh\\n");
    fi;
end;

# ============================================================================
# Add group if new (returns true if added, false if duplicate)
# ============================================================================
AddIfNew := function(G, degree, snName)
    local fp, key, idx, H, entry, gens;

    fp := GroupFingerprint(G);
    key := GroupFingerprintKey(fp);

    # Get generators as image lists
    gens := List(GeneratorsOfGroup(G), p -> ListPerm(p, degree));

    if not IsBound(db.index.(key)) then
        # New fingerprint - definitely a new group
        Add(db.groups, rec(
            fingerprint := fp,
            generators := gens,
            structure := StructureDescription(G),
            firstFoundIn := snName,
            degree := degree
        ));
        db.index.(key) := [Length(db.groups)];
        return true;
    fi;

    # Fingerprint collision - need to check isomorphism
    stats.fingerprintHits := stats.fingerprintHits + 1;

    for idx in db.index.(key) do
        entry := db.groups[idx];
        # Handle empty generators (trivial group)
        if Length(entry.generators) = 0 then
            H := Group(());
        else
            H := Group(List(entry.generators, PermList));
        fi;
        stats.isomorphismTests := stats.isomorphismTests + 1;
        if IsomorphismGroups(G, H) <> fail then
            return false;  # Duplicate
        fi;
    od;

    # New group with existing fingerprint (rare but possible)
    Add(db.groups, rec(
        fingerprint := fp,
        generators := gens,
        structure := StructureDescription(G),
        firstFoundIn := snName,
        degree := degree
    ));
    Add(db.index.(key), Length(db.groups));
    return true;
end;

# ============================================================================
# Save database to file
# ============================================================================
SaveDatabase := function(filename)
    local output;
    output := OutputTextFile(filename, false);
    SetPrintFormattingStatus(output, false);
    PrintTo(output, "return ");
    PrintTo(output, db);
    PrintTo(output, ";\\n");
    CloseStream(output);
end;

# ============================================================================
# Main enumeration
# ============================================================================

# Initialize log file
PrintTo(logFile, "Starting enumeration of subgroups of Sn (n = ", startN, " to ", maxN, ")\\n");
AppendTo(logFile, "================================================================================\\n");

# Load existing database for incremental runs
if startN > 2 then
    LoadDatabase(dbFile);
fi;

startTime := Runtime();

# Helper to write a single group entry to the groups file
WriteGroupEntry := function(idx, entry)
    local G, gens, j;
    AppendTo(groupsFile, "GROUP:", idx, "\\n");
    AppendTo(groupsFile, "FIRST_FOUND:", entry.firstFoundIn, "\\n");
    AppendTo(groupsFile, "ORDER:", entry.fingerprint.size, "\\n");
    AppendTo(groupsFile, "STRUCTURE:", entry.structure, "\\n");
    AppendTo(groupsFile, "DEGREE:", entry.degree, "\\n");
    AppendTo(groupsFile, "GENERATORS_IMAGE:");
    for j in [1..Length(entry.generators)] do
        AppendTo(groupsFile, entry.generators[j]);
        if j < Length(entry.generators) then
            AppendTo(groupsFile, ";");
        fi;
    od;
    AppendTo(groupsFile, "\\n");
    AppendTo(groupsFile, "GENERATORS_CYCLE:");
    if Length(entry.generators) = 0 then
        G := Group(());
    else
        G := Group(List(entry.generators, PermList));
    fi;
    gens := GeneratorsOfGroup(G);
    for j in [1..Length(gens)] do
        AppendTo(groupsFile, gens[j]);
        if j < Length(gens) then
            AppendTo(groupsFile, ", ");
        fi;
    od;
    AppendTo(groupsFile, "\\n");
    AppendTo(groupsFile, "GROUP_END\\n");
end;

# Initialize groups file with existing groups
PrintTo(groupsFile, "GROUPS_START\\n");
for i in [1..Length(db.groups)] do
    WriteGroupEntry(i, db.groups[i]);
od;

lastWrittenGroup := Length(db.groups);

# ============================================================================
# Conjugacy class caching functions
# ============================================================================
# conjugacyCacheDir is now passed as a parameter from Python

SaveConjugacyClasses := function(n, subgroupClasses)
    local filename, output, i, H, gens;
    filename := Concatenation(conjugacyCacheDir, "s", String(n), "_subgroups.g");
    output := OutputTextFile(filename, false);
    SetPrintFormattingStatus(output, false);
    PrintTo(output, "# Conjugacy class representatives for S", n, "\\n");
    PrintTo(output, "# ", Length(subgroupClasses), " subgroups\\n");
    PrintTo(output, "return [\\n");
    for i in [1..Length(subgroupClasses)] do
        H := Representative(subgroupClasses[i]);
        gens := List(GeneratorsOfGroup(H), p -> ListPerm(p, n));
        PrintTo(output, "  ", gens);
        if i < Length(subgroupClasses) then
            PrintTo(output, ",");
        fi;
        PrintTo(output, "\\n");
    od;
    PrintTo(output, "];\\n");
    CloseStream(output);
end;

LoadConjugacyClasses := function(n)
    local filename, data, subgroups, gens;
    filename := Concatenation(conjugacyCacheDir, "s", String(n), "_subgroups.g");
    if not IsExistingFile(filename) then
        return fail;
    fi;
    data := ReadAsFunction(filename)();
    subgroups := [];
    for gens in data do
        if Length(gens) = 0 then
            Add(subgroups, Group(()));
        else
            Add(subgroups, Group(List(gens, PermList)));
        fi;
    od;
    return subgroups;
end;

SaveProgressIndex := function(n, idx)
    local filename;
    filename := Concatenation(conjugacyCacheDir, "s", String(n), "_progress.txt");
    PrintTo(filename, idx);
end;

LoadProgressIndex := function(n)
    local filename, idx;
    filename := Concatenation(conjugacyCacheDir, "s", String(n), "_progress.txt");
    if not IsExistingFile(filename) then
        return 1;
    fi;
    idx := Int(ReadAll(InputTextFile(filename)));
    return idx;
end;

ClearProgressIndex := function(n)
    local filename;
    filename := Concatenation(conjugacyCacheDir, "s", String(n), "_progress.txt");
    if IsExistingFile(filename) then
        RemoveFile(filename);
    fi;
end;

# Create cache directory
Exec(Concatenation("mkdir -p ", conjugacyCacheDir));

for n in [startN..maxN] do
    AppendTo(logFile, "Processing S", n, "...\\n");

    Sn := SymmetricGroup(n);
    snName := Concatenation("S", String(n));

    # Try to load cached conjugacy classes, or compute them
    subgroups := LoadConjugacyClasses(n);
    if subgroups <> fail then
        AppendTo(logFile, "  Loaded ", Length(subgroups), " cached subgroups\\n");
        nSubgroups := Length(subgroups);
        startIdx := LoadProgressIndex(n);
        if startIdx > 1 then
            AppendTo(logFile, "  Resuming from index ", startIdx, "\\n");
        fi;
    else
        AppendTo(logFile, "  Computing conjugacy classes of subgroups...\\n");
        subgroupClasses := ConjugacyClassesSubgroups(Sn);
        nSubgroups := Length(subgroupClasses);
        # Convert to list of groups and cache
        subgroups := List(subgroupClasses, Representative);
        SaveConjugacyClasses(n, subgroupClasses);
        AppendTo(logFile, "  Cached ", nSubgroups, " subgroups to disk\\n");
        startIdx := 1;
    fi;

    stats.totalSubgroups := stats.totalSubgroups + nSubgroups;
    AppendTo(logFile, "  Found ", nSubgroups, " subgroups (up to conjugacy)\\n");

    newCount := 0;
    for i in [startIdx..nSubgroups] do
        H := subgroups[i];
        if AddIfNew(H, n, snName) then
            newCount := newCount + 1;

            # Write new group immediately (crash-safe)
            WriteGroupEntry(Length(db.groups), db.groups[Length(db.groups)]);
            lastWrittenGroup := Length(db.groups);
        fi;

        # Progress update and checkpoint every 100 subgroups
        if i mod 100 = 0 then
            AppendTo(logFile, "    Processed ", i, "/", nSubgroups, " subgroups (", Length(db.groups), " unique groups, checkpoint saved)\\n");
            SaveProgressIndex(n, i + 1);
            SaveDatabase(dbFile);
        fi;
    od;

    # Groups are now written immediately, no need for batch write

    elapsed := Float(Runtime() - startTime) / 1000.0;
    AppendTo(logFile, "  New groups added: ", newCount, "\\n");
    AppendTo(logFile, "  Total unique groups so far: ", Length(db.groups), "\\n");
    AppendTo(logFile, "  Time elapsed: ", elapsed, "s\\n");
    AppendTo(logFile, "--------------------------------------------------------------------------------\\n");

    # Save database and clear progress (Sn complete)
    SaveDatabase(dbFile);
    ClearProgressIndex(n);
    AppendTo(logFile, "  Database checkpoint saved to ", dbFile, "\\n");
od;

# ============================================================================
# Output results
# ============================================================================
AppendTo(logFile, "================================================================================\\n");
AppendTo(logFile, "SUMMARY\\n");
AppendTo(logFile, "Total subgroups processed: ", stats.totalSubgroups, "\\n");
AppendTo(logFile, "Total unique groups: ", Length(db.groups), "\\n");
AppendTo(logFile, "Fingerprint collisions: ", stats.fingerprintHits, "\\n");
AppendTo(logFile, "Isomorphism tests performed: ", stats.isomorphismTests, "\\n");
totalTime := Float(Runtime() - startTime) / 1000.0;
AppendTo(logFile, "Total time: ", totalTime, "s\\n");
AppendTo(logFile, "================================================================================\\n");

# ============================================================================
# Finalize groups file (groups were written incrementally above)
# ============================================================================
AppendTo(groupsFile, "GROUPS_END\\n");

AppendTo(logFile, "DONE\\n");

QUIT;
'''


def parse_groups_file(filepath: str) -> list:
    """Parse the GAP groups output file."""
    groups = []
    current_group = {}

    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        return []

    lines = content.split('\n')
    in_groups = False

    for line in lines:
        line = line.strip()

        if line == 'GROUPS_START':
            in_groups = True
        elif line == 'GROUPS_END':
            in_groups = False
        elif in_groups:
            if line.startswith('GROUP:'):
                current_group = {'number': int(line[6:])}
            elif line.startswith('FIRST_FOUND:'):
                current_group['first_found'] = line[12:]
            elif line.startswith('ORDER:'):
                current_group['order'] = int(line[6:])
            elif line.startswith('STRUCTURE:'):
                current_group['structure'] = line[10:]
            elif line.startswith('DEGREE:'):
                current_group['degree'] = int(line[7:])
            elif line.startswith('GENERATORS_IMAGE:'):
                current_group['generators_image'] = line[17:]
            elif line.startswith('GENERATORS_CYCLE:'):
                current_group['generators_cycle'] = line[17:]
            elif line == 'GROUP_END':
                groups.append(current_group)
                current_group = {}

    return groups


def write_final_output(groups: list, output_dir: Path):
    """Write the final formatted output files."""

    # Write groups file
    groups_file = output_dir / 'subgroups_of_Sn.txt'
    with open(groups_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("SUBGROUPS OF SYMMETRIC GROUPS UP TO ISOMORPHISM\n")
        f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Total unique groups: {len(groups)}\n")
        f.write("=" * 80 + "\n\n")

        # Sort by order, then by first appearance
        def sort_key(g):
            sn_order = {'S1': 1, 'S2': 2, 'S3': 3, 'S4': 4, 'S5': 5,
                       'S6': 6, 'S7': 7, 'S8': 8, 'S9': 9, 'S10': 10,
                       'S11': 11, 'S12': 12, 'S13': 13, 'S14': 14, 'S15': 15}
            return (g.get('order', 0), sn_order.get(g.get('first_found', 'S1'), 99))

        groups_sorted = sorted(groups, key=sort_key)

        for i, g in enumerate(groups_sorted, 1):
            f.write("=" * 80 + "\n")
            f.write(f"Group #{i}\n")
            f.write(f"First appeared in: {g.get('first_found', 'Unknown')}\n")
            f.write(f"Order: {g.get('order', 'Unknown')}\n")
            f.write(f"Structure: {g.get('structure', 'Unknown')}\n")
            f.write(f"Degree: {g.get('degree', 'Unknown')}\n")
            f.write(f"Generators (cycle notation): {g.get('generators_cycle', 'Unknown')}\n")
            f.write(f"Generators (image list): {g.get('generators_image', 'Unknown')}\n")
            f.write("=" * 80 + "\n\n")

    print(f"Groups written to: {groups_file}")

    # Also save as JSON for programmatic access
    json_file = output_dir / 'subgroups_of_Sn.json'
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(groups_sorted, f, indent=2)

    print(f"JSON data written to: {json_file}")


def windows_to_cygwin_path(win_path: str) -> str:
    """Convert Windows path to Cygwin path."""
    # C:\Users\... -> /cygdrive/c/Users/...
    path = str(win_path).replace('\\', '/')
    if len(path) >= 2 and path[1] == ':':
        drive = path[0].lower()
        path = f'/cygdrive/{drive}{path[2:]}'
    return path


def main():
    parser = argparse.ArgumentParser(
        description='Enumerate subgroups of symmetric groups up to isomorphism'
    )
    parser.add_argument('--start-n', type=int, default=2,
                       help='Starting symmetric group (default: 2)')
    parser.add_argument('--max-n', type=int, default=8,
                       help='Maximum symmetric group (default: 8)')
    parser.add_argument('--output-dir', type=str, default='.',
                       help='Output directory (default: current directory)')

    args = parser.parse_args()

    output_dir = Path(args.output_dir).resolve()
    output_dir.mkdir(parents=True, exist_ok=True)

    # File paths (convert to Cygwin paths for GAP)
    db_file = windows_to_cygwin_path(output_dir / 'subgroups_db.g')
    gap_log_file = windows_to_cygwin_path(output_dir / 'gap_log.txt')
    gap_groups_file = windows_to_cygwin_path(output_dir / 'gap_groups.txt')
    cache_dir = windows_to_cygwin_path(output_dir / 'conjugacy_cache') + '/'

    # Ensure cache directory exists
    (output_dir / 'conjugacy_cache').mkdir(parents=True, exist_ok=True)

    print(f"Enumerating subgroups of S{args.start_n} through S{args.max_n}")
    print(f"Output directory: {output_dir}")
    print("=" * 60)

    # Generate GAP script
    gap_code = generate_gap_script(args.start_n, args.max_n, db_file,
                                   gap_log_file, gap_groups_file, cache_dir)
    gap_script = output_dir / 'enumerate_subgroups.g'

    with open(gap_script, 'w', encoding='utf-8') as f:
        f.write(gap_code)

    print(f"GAP script written to: {gap_script}")
    print("Running GAP (this may take a while)...")
    print("=" * 60)
    sys.stdout.flush()

    # Run GAP via Cygwin bash (Windows GAP installation uses Cygwin)
    gap_bash = r"C:\Program Files\GAP-4.15.1\runtime\bin\bash.exe"
    gap_script_cygwin = windows_to_cygwin_path(gap_script)
    # Quote the path in case of spaces
    cmd = f'/opt/gap-4.15.1/gap -q "{gap_script_cygwin}"'

    print(f"Using Cygwin bash: {gap_bash}")
    print(f"GAP command: {cmd}")

    process = subprocess.Popen(
        [gap_bash, '--login', '-c', cmd],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        cwd=r"C:\Program Files\GAP-4.15.1\runtime\bin"
    )

    # Stream output to console and file
    gap_output_file = output_dir / 'gap_output.txt'
    with open(gap_output_file, 'w', encoding='utf-8') as f:
        for line in iter(process.stdout.readline, ''):
            print(line, end='')
            f.write(line)
            f.flush()
            sys.stdout.flush()

    process.wait()
    print(f"\nGAP process completed with return code: {process.returncode}")

    if process.returncode != 0:
        print("GAP Error - check gap_output.txt for details")
        sys.exit(1)

    print("=" * 60)

    # Convert Cygwin path back to Windows for file reading
    gap_groups_file_win = str(output_dir / 'gap_groups.txt')
    gap_log_file_win = str(output_dir / 'gap_log.txt')

    # Parse the groups file
    groups = parse_groups_file(gap_groups_file_win)
    print(f"Enumeration complete. Found {len(groups)} unique groups.")

    # Write final formatted output
    write_final_output(groups, output_dir)

    # Copy log to final location
    final_log = output_dir / 'enumeration_log.txt'
    try:
        with open(gap_log_file_win, 'r', encoding='utf-8') as f:
            log_content = f.read()
        with open(final_log, 'w', encoding='utf-8') as f:
            f.write(f"Subgroup Enumeration Log\n")
            f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 80 + "\n\n")
            f.write(log_content)
        print(f"Log written to: {final_log}")
    except FileNotFoundError:
        print("Warning: Log file not found")


if __name__ == '__main__':
    main()
