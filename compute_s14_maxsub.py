#!/usr/bin/env python3
"""
compute_s14_maxsub.py - Compute A005432(14) = 75,154 via maximal subgroup decomposition

Phase A: Compute subgroup lattices of each maximal subgroup of S14 (parallel)
Phase B: Deduplicate all subgroups by S14-conjugacy (single process)

Architecture:
  - Each maximal subgroup gets its own GAP worker process
  - Workers save incrementally to checkpoint files in maxsub_output/
  - After all workers complete, Phase B loads all results and deduplicates
  - Final output: conjugacy_cache/s14_subgroups.g

Memory allocation:
  - Small maxsubs (wreath products, primitives): 4-8GB
  - Medium maxsubs (S_k x S_{14-k}, k >= 4): 8-16GB
  - Large maxsubs (S_1xS_13, S_2xS_12, S_3xS_11): 16-32GB
  - Phase B deduplication: 50GB
"""

import subprocess
import sys
import os
import time
from pathlib import Path
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed

# ============================================================================
# Configuration
# ============================================================================

GAP_BASH = r"C:\Program Files\GAP-4.15.1\runtime\bin\bash.exe"
BASE_DIR = Path(r"C:\Users\jeffr\Downloads\Symmetric Groups")
OUTPUT_DIR = BASE_DIR / "maxsub_output"
LOG_DIR = BASE_DIR / "maxsub_output"
CACHE_DIR = BASE_DIR / "conjugacy_cache"

N = 14
EXPECTED_COUNT = 75154

# Timeout per worker (hours)
DEFAULT_TIMEOUT = 8 * 3600  # 8 hours
LARGE_TIMEOUT = 24 * 3600   # 24 hours for very large maxsubs

def windows_to_cygwin_path(win_path: str) -> str:
    """Convert Windows path to Cygwin path."""
    path = str(win_path).replace('\\', '/')
    if len(path) >= 2 and path[1] == ':':
        drive = path[0].lower()
        path = f'/cygdrive/{drive}{path[2:]}'
    return path

BASE_CYGWIN = windows_to_cygwin_path(str(BASE_DIR))

# ============================================================================
# Worker definitions
#
# Each worker is defined by:
#   label:       unique name for file output
#   type:        "intransitive", "wreath", "primitive", "s1xs13"
#   params:      type-specific parameters
#   memory:      GAP -o flag (max memory)
#   timeout:     max seconds
#   phase:       execution phase (workers in same phase run in parallel)
# ============================================================================

WORKERS = [
    # Phase 1: Largest maximal subgroups (run 2-3 at a time)
    {
        "label": "intrans_1x13",
        "type": "s1xs13",
        "params": [],
        "memory": "16g",
        "timeout": LARGE_TIMEOUT,
        "phase": 1,
    },
    {
        "label": "intrans_2x12",
        "type": "intransitive",
        "params": [2],
        "memory": "32g",
        "timeout": LARGE_TIMEOUT,
        "phase": 1,
    },
    {
        "label": "intrans_3x11",
        "type": "intransitive",
        "params": [3],
        "memory": "32g",
        "timeout": LARGE_TIMEOUT,
        "phase": 1,
    },

    # Phase 2: Medium intransitive maxsubs
    {
        "label": "intrans_4x10",
        "type": "intransitive",
        "params": [4],
        "memory": "16g",
        "timeout": DEFAULT_TIMEOUT,
        "phase": 2,
    },
    {
        "label": "intrans_5x9",
        "type": "intransitive",
        "params": [5],
        "memory": "16g",
        "timeout": DEFAULT_TIMEOUT,
        "phase": 2,
    },
    {
        "label": "intrans_6x8",
        "type": "intransitive",
        "params": [6],
        "memory": "16g",
        "timeout": DEFAULT_TIMEOUT,
        "phase": 2,
    },
    {
        "label": "intrans_7x7",
        "type": "intransitive",
        "params": [7],
        "memory": "16g",
        "timeout": DEFAULT_TIMEOUT,
        "phase": 2,
    },

    # Phase 3: Wreath products and primitives (smaller, run all in parallel)
    {
        "label": "wreath_2wr7",
        "type": "wreath",
        "params": [2, 7],
        "memory": "8g",
        "timeout": DEFAULT_TIMEOUT,
        "phase": 3,
    },
    {
        "label": "wreath_7wr2",
        "type": "wreath",
        "params": [7, 2],
        "memory": "8g",
        "timeout": DEFAULT_TIMEOUT,
        "phase": 3,
    },
]

# Primitive groups will be added dynamically


def generate_worker_script(worker: dict) -> str:
    """Generate a self-contained GAP script for a single worker.

    Scripts are self-contained (not using Read for the template) to avoid
    GAP's restriction on QUIT inside Read() context.
    """

    label = worker["label"]
    wtype = worker["type"]
    params = worker["params"]
    output_cygwin = windows_to_cygwin_path(str(OUTPUT_DIR / f"{label}.g"))

    # Common preamble: load core functions
    preamble = f'''# Worker script for maximal subgroup: {label}
# Generated by compute_s14_maxsub.py at {datetime.now()}

MAXSUB_BASE := "{BASE_CYGWIN}";
MAXSUB_OUTPUT := Concatenation(MAXSUB_BASE, "/maxsub_output");
MAXSUB_CACHE := Concatenation(MAXSUB_BASE, "/conjugacy_cache");

Read(Concatenation(MAXSUB_BASE, "/compute_s14_maxsub.g"));

Print("Worker started: type={wtype}, label={label}\\n");
startTime := Runtime();
n := {N};
'''

    if wtype == "s1xs13":
        body = f'''
# Special case: use cached S13 subgroups
Print("Loading S13 cache and embedding as S1 x S13...\\n");
cacheFile := Concatenation(MAXSUB_CACHE, "/s13_subgroups.g");
embeddedSubs := EmbedS13SubgroupsAsS1xS13(cacheFile, n);

# Write directly to output
PrintTo("{output_cygwin}", "# Subgroups of S1 x S13 (from S13 cache)\\n");
AppendTo("{output_cygwin}", "# Count: ", Length(embeddedSubs), "\\n");
AppendTo("{output_cygwin}", "maxsub_results := [\\n");

for i in [1..Length(embeddedSubs)] do
    entry := embeddedSubs[i];
    gens := GeneratorsOfGroup(entry.group);
    genImages := [];
    for g in gens do
        Add(genImages, ListPerm(g, n));
    od;

    if i > 1 then
        AppendTo("{output_cygwin}", ",\\n");
    fi;
    AppendTo("{output_cygwin}", "  rec(gens := ", genImages,
             ", inv := ", entry.inv,
             ", source := \\"intrans_1x13\\")");

    if i mod 2000 = 0 then
        Print("  Written ", i, "/", Length(embeddedSubs), "\\n");
        GASMAN("collect");
    fi;
od;

AppendTo("{output_cygwin}", "\\n];\\n");

elapsed := Runtime() - startTime;
Print("\\n=== S1 x S13 worker complete ===\\n");
Print("  Subgroups: ", Length(embeddedSubs), "\\n");
Print("  Time: ", Int(elapsed/1000), " seconds\\n");
AppendTo("{output_cygwin}", "# Complete: ", Length(embeddedSubs),
         " subgroups in ", Int(elapsed/1000), " seconds\\n");
'''

    elif wtype == "intransitive":
        k = params[0]
        body = f'''
k := {k};
Print("Building S_", k, " x S_", n-k, " on {{1,...,", n, "}}...\\n");
M := BuildIntransitiveMaxSub(k, n);
workerLabel := "intrans_{k}x{N - k}";

Print("Maximal subgroup: ", workerLabel, "\\n");
Print("  Order: ", Size(M), "\\n");

count := ComputeSubgroupsOfMaxSub(M, workerLabel, "{output_cygwin}", n);

elapsed := Runtime() - startTime;
AppendTo("{output_cygwin}", "# Complete: ", count,
         " subgroups in ", Int(elapsed/1000), " seconds\\n");

Print("\\n=== Worker ", workerLabel, " complete ===\\n");
Print("  Subgroups: ", count, "\\n");
Print("  Total time: ", Int(elapsed/1000), " seconds\\n");
'''

    elif wtype == "wreath":
        a, b = params
        body = f'''
Print("Building S_{a} wr S_{b}...\\n");
M := BuildWreathMaxSub({a}, {b});
workerLabel := "wreath_{a}wr{b}";

Print("Maximal subgroup: ", workerLabel, "\\n");
Print("  Order: ", Size(M), "\\n");

count := ComputeSubgroupsOfMaxSub(M, workerLabel, "{output_cygwin}", n);

elapsed := Runtime() - startTime;
AppendTo("{output_cygwin}", "# Complete: ", count,
         " subgroups in ", Int(elapsed/1000), " seconds\\n");

Print("\\n=== Worker ", workerLabel, " complete ===\\n");
Print("  Subgroups: ", count, "\\n");
Print("  Total time: ", Int(elapsed/1000), " seconds\\n");
'''

    elif wtype == "primitive":
        idx = params[0]
        body = f'''
Print("Loading PrimitiveGroup({N}, {idx})...\\n");
M := PrimitiveGroup({N}, {idx});
workerLabel := "primitive_{idx}";

Print("Maximal subgroup: ", workerLabel, "\\n");
Print("  Order: ", Size(M), "\\n");

count := ComputeSubgroupsOfMaxSub(M, workerLabel, "{output_cygwin}", n);

elapsed := Runtime() - startTime;
AppendTo("{output_cygwin}", "# Complete: ", count,
         " subgroups in ", Int(elapsed/1000), " seconds\\n");

Print("\\n=== Worker ", workerLabel, " complete ===\\n");
Print("  Subgroups: ", count, "\\n");
Print("  Total time: ", Int(elapsed/1000), " seconds\\n");
'''

    else:
        body = f'''
Print("ERROR: Unknown worker type: {wtype}\\n");
'''

    return preamble + body + "\nQUIT;\n"


def generate_primitive_workers() -> list:
    """Generate worker definitions for primitive maximal subgroups.

    We need GAP to tell us how many primitive groups of degree 14 there are.
    Run a quick GAP query to get this info.
    """
    print("Querying GAP for primitive groups of degree 14...")

    query_script = f'''
nrPrim := NrPrimitiveGroups({N});
Print("NRPRIM=", nrPrim, "\\n");
for i in [1..nrPrim] do
    G := PrimitiveGroup({N}, i);
    ord := Size(G);
    # Skip S_n and A_n
    if ord < Factorial({N}) and ord < Factorial({N})/2 then
        Print("PRIM=", i, ",", ord, "\\n");
    fi;
od;
QUIT;
'''
    script_file = OUTPUT_DIR / "query_primitives.g"
    script_cygwin = windows_to_cygwin_path(str(script_file))
    with open(script_file, 'w') as f:
        f.write(query_script)

    cmd = f'/opt/gap-4.15.1/gap -q "{script_cygwin}"'
    proc = subprocess.run(
        [GAP_BASH, '--login', '-c', cmd],
        capture_output=True, text=True, timeout=60
    )

    workers = []
    for line in proc.stdout.strip().split('\n'):
        line = line.strip()
        if line.startswith("PRIM="):
            parts = line[5:].split(',')
            idx = int(parts[0])
            order = int(parts[1])
            workers.append({
                "label": f"primitive_{idx}",
                "type": "primitive",
                "params": [idx],
                "memory": "4g",
                "timeout": DEFAULT_TIMEOUT,
                "phase": 3,
            })
            print(f"  PrimitiveGroup(14, {idx}): order {order}")

    print(f"  Found {len(workers)} non-trivial primitive maximal subgroups\n")
    return workers


def run_worker(worker: dict) -> dict:
    """Run a single GAP worker process."""
    label = worker["label"]
    memory = worker["memory"]
    timeout = worker["timeout"]

    # Generate and write the GAP script
    script = generate_worker_script(worker)
    script_file = OUTPUT_DIR / f"worker_{label}.g"
    with open(script_file, 'w') as f:
        f.write(script)

    script_cygwin = windows_to_cygwin_path(str(script_file))
    log_file = LOG_DIR / f"worker_{label}.log"

    cmd = f'/opt/gap-4.15.1/gap -q -o {memory} "{script_cygwin}"'

    start_time = time.time()
    result = {
        "label": label,
        "success": False,
        "elapsed": 0,
        "returncode": -1,
        "error": None,
    }

    try:
        with open(log_file, 'w') as log:
            log.write(f"# Worker: {label}\n")
            log.write(f"# Started: {datetime.now()}\n")
            log.write(f"# Memory: {memory}\n")
            log.write(f"# Command: {cmd}\n\n")
            log.flush()

            proc = subprocess.Popen(
                [GAP_BASH, '--login', '-c', cmd],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
            )

            for line in proc.stdout:
                log.write(line)
                log.flush()
                # Print key progress lines to console
                if any(kw in line for kw in ["Computing", "Found", "Complete", "ERROR", "Saved"]):
                    print(f"  [{label}] {line.rstrip()}")

            proc.wait(timeout=timeout)
            result["returncode"] = proc.returncode

    except subprocess.TimeoutExpired:
        proc.kill()
        result["error"] = f"Timeout after {timeout}s"
        print(f"  [{label}] TIMEOUT after {timeout/3600:.1f} hours")
    except Exception as e:
        result["error"] = str(e)
        print(f"  [{label}] ERROR: {e}")

    elapsed = time.time() - start_time
    result["elapsed"] = elapsed

    # Check if output file was created
    output_file = OUTPUT_DIR / f"{label}.g"
    if output_file.exists() and output_file.stat().st_size > 100:
        result["success"] = True
        print(f"  [{label}] Done in {elapsed:.0f}s (exit code {result['returncode']})")
    else:
        result["success"] = False
        if not result["error"]:
            result["error"] = "Output file missing or empty"
        print(f"  [{label}] FAILED: {result['error']}")

    return result


def run_phase(phase_num: int, workers: list, max_parallel: int) -> list:
    """Run all workers in a phase with controlled parallelism."""
    phase_workers = [w for w in workers if w["phase"] == phase_num]
    if not phase_workers:
        return []

    print(f"\n{'='*60}")
    print(f"Phase {phase_num}: {len(phase_workers)} workers (max {max_parallel} parallel)")
    print(f"{'='*60}")

    for w in phase_workers:
        print(f"  - {w['label']} (memory: {w['memory']})")
    print()

    results = []
    with ProcessPoolExecutor(max_workers=max_parallel) as executor:
        futures = {executor.submit(run_worker, w): w for w in phase_workers}
        for future in as_completed(futures):
            worker = futures[future]
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                print(f"  [{worker['label']}] Exception: {e}")
                results.append({
                    "label": worker["label"],
                    "success": False,
                    "elapsed": 0,
                    "error": str(e),
                })

    return results


def run_phase_b():
    """Run the deduplication phase."""
    print(f"\n{'='*60}")
    print("Phase B: Deduplication")
    print(f"{'='*60}")

    script_cygwin = windows_to_cygwin_path(str(BASE_DIR / "deduplicate_maxsub.g"))
    log_file = LOG_DIR / "deduplicate.log"

    cmd = f'/opt/gap-4.15.1/gap -q -o 50g "{script_cygwin}"'

    print(f"Command: {cmd}")
    print(f"Log: {log_file}")
    print()

    start_time = time.time()

    with open(log_file, 'w') as log:
        log.write(f"# Deduplication phase\n")
        log.write(f"# Started: {datetime.now()}\n\n")

        proc = subprocess.Popen(
            [GAP_BASH, '--login', '-c', cmd],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
        )

        for line in proc.stdout:
            print(line, end='')
            sys.stdout.flush()
            log.write(line)
            log.flush()

        proc.wait()

        elapsed = time.time() - start_time
        log.write(f"\n# Finished: {datetime.now()}\n")
        log.write(f"# Exit code: {proc.returncode}\n")
        log.write(f"# Elapsed: {elapsed:.0f}s\n")

    print(f"\nDeduplication completed in {elapsed:.0f}s (exit code {proc.returncode})")
    return proc.returncode


def check_existing_outputs() -> list:
    """Check which worker outputs already exist (for resume support)."""
    existing = []
    for f in OUTPUT_DIR.glob("*.g"):
        if f.name.startswith("worker_") or f.name.startswith("query_"):
            continue
        if f.stat().st_size > 100:
            # Check if the file has a "Complete" marker
            with open(f, 'r') as fh:
                content = fh.read()
                if "# Complete:" in content:
                    label = f.stem
                    existing.append(label)
    return existing


def main():
    print("=" * 60)
    print("A005432(14) = 75,154 via Maximal Subgroup Decomposition")
    print("=" * 60)
    print(f"Started: {datetime.now()}")
    print(f"Output dir: {OUTPUT_DIR}")
    print()

    # Create output directory
    OUTPUT_DIR.mkdir(exist_ok=True)
    CACHE_DIR.mkdir(exist_ok=True)

    # Check for existing completed outputs (resume support)
    existing = check_existing_outputs()
    if existing:
        print(f"Found {len(existing)} existing completed outputs:")
        for label in sorted(existing):
            print(f"  - {label}")
        print()

    # Get primitive group workers
    prim_workers = generate_primitive_workers()

    # Build full worker list
    all_workers = WORKERS + prim_workers

    # Skip already-completed workers
    workers_to_run = [w for w in all_workers if w["label"] not in existing]
    skipped = [w for w in all_workers if w["label"] in existing]

    if skipped:
        print(f"Skipping {len(skipped)} already-completed workers:")
        for w in skipped:
            print(f"  - {w['label']}")
        print()

    print(f"Workers to run: {len(workers_to_run)}")
    print()

    # ========================================================================
    # Phase A: Run workers
    # ========================================================================

    all_results = []
    overall_start = time.time()

    if workers_to_run:
        # Phase 1: Large maxsubs (2-3 at a time due to memory)
        results = run_phase(1, workers_to_run, max_parallel=3)
        all_results.extend(results)

        # Phase 2: Medium maxsubs (4 at a time)
        results = run_phase(2, workers_to_run, max_parallel=4)
        all_results.extend(results)

        # Phase 3: Small maxsubs (all at once)
        results = run_phase(3, workers_to_run, max_parallel=8)
        all_results.extend(results)

    # Summary of Phase A
    phase_a_elapsed = time.time() - overall_start
    print(f"\n{'='*60}")
    print("Phase A Summary")
    print(f"{'='*60}")

    succeeded = [r for r in all_results if r["success"]]
    failed = [r for r in all_results if not r["success"]]

    print(f"  Completed: {len(succeeded)}/{len(all_results)}")
    print(f"  Previously completed: {len(skipped)}")
    print(f"  Failed: {len(failed)}")
    print(f"  Phase A time: {phase_a_elapsed:.0f}s ({phase_a_elapsed/3600:.1f}h)")

    if failed:
        print("\n  Failed workers:")
        for r in failed:
            print(f"    - {r['label']}: {r.get('error', 'unknown error')}")

        print("\n  WARNING: Some workers failed. Proceeding to Phase B anyway.")
        print("  Results may be incomplete. Re-run to retry failed workers.")

    # ========================================================================
    # Phase B: Deduplication
    # ========================================================================

    print()
    rc = run_phase_b()

    total_elapsed = time.time() - overall_start
    print(f"\n{'='*60}")
    print("Final Summary")
    print(f"{'='*60}")
    print(f"  Total time: {total_elapsed:.0f}s ({total_elapsed/3600:.1f}h)")
    print(f"  Output: {CACHE_DIR / 's14_subgroups.g'}")
    print(f"  Phase B exit code: {rc}")
    print(f"  Finished: {datetime.now()}")

    return rc


if __name__ == "__main__":
    sys.exit(main())
